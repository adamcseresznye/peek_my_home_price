{
 "cells": [
  {
   "cell_type": "raw",
   "id": "ecb309f7",
   "metadata": {},
   "source": [
    "---\n",
    "title: 'Peek My Home Price Part-5: Fine tuning'\n",
    "author: Adam Cseresznye\n",
    "date: '2024-11-24'\n",
    "categories:\n",
    "  - Belgian Housing Market Insights\n",
    "jupyter: python3\n",
    "toc: true\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "    code-tools: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab5a692-e95d-4785-8d85-ed1cc10b4056",
   "metadata": {
    "tags": []
   },
   "source": [
    "![Photo by Christian Allard UnSplash](https://images.unsplash.com/photo-1549407408-4b016f497e4d?q=80&w=2070&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D){fig-align=\"center\" width=50%}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e955da8b-ac66-47c9-95ba-2c66f68fe821",
   "metadata": {},
   "source": [
    "In Part 4, we established a robust cross-validation strategy to consistently assess our model's performance across multiple data folds. We also identified and managed potential outliers in our dataset. Additionally, we explored diverse feature engineering methods, creating and evaluating informative features to enhance our model's predictive capabilities. \n",
    "\n",
    "In this final segment, we'll optimize our hyperparameters using Optuna and end by evaluating the final model's performance based on the test portion. Let's dive in!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b335e7b-e371-4745-a683-7484741176b5",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "You can explore the project's app on its [website](https://peek-my-home-price.fly.dev/). For more details, visit the [GitHub repository](https://github.com/adamcseresznye/peek_my_home_price).\n",
    "\n",
    "Check out the series for a deeper dive:\n",
    "- [Part 1: Characterizing the Data](https://adamcseresznye.github.io/blog/projects/peek_my_home_price/part-1_characterizing_the_data.html)\n",
    "- [Part 2: Building a Baseline Model](https://adamcseresznye.github.io/blog/projects/peek_my_home_price/part-2_building_a_baseline_model.html)\n",
    "- [Part 3: Feature Selection](https://adamcseresznye.github.io/blog/projects/peek_my_home_price/part-3_feature_selection.html)\n",
    "- [Part 4: Feature Engineering](https://adamcseresznye.github.io/blog/projects/peek_my_home_price/part-4_feature_engineering.html)\n",
    "- [Part 5: Fine-Tuning](https://adamcseresznye.github.io/blog/projects/peek_my_home_price/part-5_fine_tuning.html)\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e260a44-75c8-4731-98e9-faaea802ae6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path.cwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3c6a54-530c-4491-bb08-3dfc054d78a6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Any, List, Optional, Tuple\n",
    "\n",
    "import catboost\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lets_plot import *\n",
    "from lets_plot.mapping import as_discrete\n",
    "from sklearn import metrics, model_selection\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from helper import pre_process, predict_model, train_model, utils\n",
    "\n",
    "LetsPlot.setup_html()\n",
    "import pickle\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573b6b77-057c-4638-886b-8ad644fef0e6",
   "metadata": {},
   "source": [
    "\n",
    "Up to this point, we've successfully gathered all the house advertisements from various sources. We've conducted data description, preselected features, established an effective data pre-processing pipeline, and identified the most suitable machine learning algorithm for this task. Additionally, we've engaged in feature engineering and carried out further feature selection to streamline our machine learning model. The final step, that's yet to be done, involves fine-tuning the hyperparameters of our machine learning model, enhancing predictive accuracy while mitigating overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86846c91-1d46-4c2e-8fb2-72f5c5b8e8fd",
   "metadata": {},
   "source": [
    "# Prepare dataframe before modelling\n",
    "\n",
    "Let's get our data ready for modeling by applying the \"prepare_data_for_modelling\" function as detailed in Part 4. A quick recap: this function carries out the subsequent actions to prepare a DataFrame for machine learning:\r\n",
    "1. It randomly shuffles the DataFrame's rows.\r\n",
    "2. The 'price' column is transformed into the base 10 logarithm.\r\n",
    "3. Categorical variable missing values are replaced with 'missing value.'\r\n",
    "4. It divides the data into features (X) and the target (y).\r\n",
    "5. Using LocalOutlierFactor, it identifies and removes outlier values.rFactor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238557b9-5614-470c-a654-24a87300eef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\n",
    "    Path.cwd().joinpath(\"data\").joinpath(\"2023-10-01_Processed_dataset_for_NB_use.gzip\")\n",
    ")\n",
    "\n",
    "X, y = pre_process.prepare_data_for_modelling(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cebf5cb-ac40-4f2e-9707-2d4243318c86",
   "metadata": {},
   "source": [
    "We'll divide the data into training and testing sets. The training portion will be dedicated to hyperparameter tuning. It's worth noting that, to guard against overfitting during hyperparameter tuning, we'll implement cross-validation. This involves splitting the training set into subgroups for training and validation. The validation portion helps prevent overfitting, and the training continues until we achieve the desired performance. The test set will come into play later for evaluating our final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abad7188-255c-4368-a465-89036ac474f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=utils.Configuration.seed,\n",
    ")\n",
    "\n",
    "print(f\"Shape of X_train: {X_train.shape}, Shape of X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66110d3b-80e1-47d7-aaba-4d1fe9d7749c",
   "metadata": {},
   "source": [
    "We'll also create a handy helper function called `dumper`. This function enables us to save the best parameters discovered during tuning as a `.pickle` file, allowing us to load and utilize these parameters from the saved file at a later time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc7f748-f9af-463e-85f3-82dca4029cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dumper(file: Any, name: str) -> None:\n",
    "    \"\"\"\n",
    "    Pickle and save an object to a file.\n",
    "\n",
    "    This function takes an object and a name, then uses the Pickle library to serialize\n",
    "    and save the object to a file with the given name. The file is saved in binary mode ('wb').\n",
    "\n",
    "    Args:\n",
    "        file (Any): The object to be pickled and saved.\n",
    "        name (str): The name of the file, including the file extension, where the object will be saved.\n",
    "\n",
    "    Returns:\n",
    "        None: This function does not return a value.\n",
    "\n",
    "    Example:\n",
    "        To save an object to a file:\n",
    "        >>> my_data = [1, 2, 3]\n",
    "        >>> dumper(my_data, \"my_data.pickle\")\n",
    "\n",
    "    Note:\n",
    "        The file is saved in binary mode ('wb') to ensure compatibility and proper\n",
    "        handling of binary data.\n",
    "    \"\"\"\n",
    "    pickle.dump(file, open(f\"{name}.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6626df1b-baef-4bbc-afcd-8a8140e89ecb",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning using Optuna\n",
    "\n",
    "To identify the most optimal settings, we'll leverage the Optuna library. The key hyperparameters under consideration are iterations, depth, learning_rate, random_strength, bagging_temperature, and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da415f11-f41b-47f6-b1dc-b29827061363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial) -> float:\n",
    "    \"\"\"\n",
    "    Optuna objective function for tuning CatBoost hyperparameters.\n",
    "\n",
    "    This function takes an Optuna trial and explores hyperparameters for a CatBoost\n",
    "    model to minimize the Root Mean Squared Error (RMSE) using K-Fold cross-validation.\n",
    "\n",
    "    Parameters:\n",
    "    - trial (optuna.Trial): Optuna trial object for hyperparameter optimization.\n",
    "\n",
    "    Returns:\n",
    "    - float: Mean RMSE across K-Fold cross-validation iterations.\n",
    "\n",
    "    Example use case:\n",
    "    # Create an Optuna study and optimize hyperparameters\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=100)\n",
    "\n",
    "    # Get the best hyperparameters\n",
    "    best_params = study.best_params\n",
    "    \"\"\"\n",
    "    catboost_params = {\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 10, 1000),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 8),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 1),\n",
    "        \"random_strength\": trial.suggest_float(\"random_strength\", 1e-9, 10),\n",
    "        \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0, 1),\n",
    "        \"l2_leaf_reg\": trial.suggest_int(\"l2_leaf_reg\", 2, 30),\n",
    "        \"border_count\": trial.suggest_int(\"border_count\", 1, 255),\n",
    "        \"thread_count\": os.cpu_count(),\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "    # Extract feature names and data types\n",
    "    # features = X.columns[~X.columns.str.contains(\"price\")]\n",
    "    # numerical_features = X.select_dtypes(\"number\").columns.to_list()\n",
    "    categorical_features = X.select_dtypes(\"object\").columns.to_list()\n",
    "\n",
    "    # Create a K-Fold cross-validator\n",
    "    CV = model_selection.RepeatedKFold(\n",
    "        n_splits=10, n_repeats=1, random_state=utils.Configuration.seed\n",
    "    )\n",
    "\n",
    "    for train_fold_index, val_fold_index in CV.split(X):\n",
    "        X_train_fold, X_val_fold = X.loc[train_fold_index], X.loc[val_fold_index]\n",
    "        y_train_fold, y_val_fold = y.loc[train_fold_index], y.loc[val_fold_index]\n",
    "\n",
    "        # Create CatBoost datasets\n",
    "        catboost_train = catboost.Pool(\n",
    "            X_train_fold,\n",
    "            y_train_fold,\n",
    "            cat_features=categorical_features,\n",
    "        )\n",
    "        catboost_valid = catboost.Pool(\n",
    "            X_val_fold,\n",
    "            y_val_fold,\n",
    "            cat_features=categorical_features,\n",
    "        )\n",
    "\n",
    "        # Initialize and train the CatBoost model\n",
    "        model = catboost.CatBoostRegressor(**catboost_params)\n",
    "        model.fit(\n",
    "            catboost_train,\n",
    "            eval_set=[catboost_valid],\n",
    "            early_stopping_rounds=utils.Configuration.early_stopping_round,\n",
    "            verbose=utils.Configuration.verbose,\n",
    "            use_best_model=True,\n",
    "        )\n",
    "\n",
    "        # Calculate OOF validation predictions\n",
    "        valid_pred = model.predict(X_val_fold)\n",
    "\n",
    "        RMSE_score = metrics.mean_squared_error(y_val_fold, valid_pred, squared=False)\n",
    "\n",
    "        del (\n",
    "            X_train_fold,\n",
    "            y_train_fold,\n",
    "            X_val_fold,\n",
    "            y_val_fold,\n",
    "            catboost_train,\n",
    "            catboost_valid,\n",
    "            model,\n",
    "            valid_pred,\n",
    "        )\n",
    "        gc.collect()\n",
    "\n",
    "        results.append(RMSE_score)\n",
    "    return np.mean(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aab0466-db29-421b-a400-6dff4cd86fd7",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "Similar to Part 4, the hyperparameter optimization step was pre-computed due to the significant computational time needed. The results were saved rather than executed during notebook rendering to save time. However, note that the outcomes should remain unchanged.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72511d93-ac86-431b-9814-e326510efba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(train_model.Optuna_Objective(X_train, y_train), n_trials=100, show_progress_bar=True)\n",
    "\n",
    "dumper(study.best_params, \"CatBoost_params\")\n",
    "dumper(study.best_value, \"CatBoost_value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f36359c-0c20-4c54-8861-2fcf36169ac9",
   "metadata": {},
   "source": [
    "As shown below, Optuna found the best Out-Of-Fold (OOF) score using the selected parameters, which is 0.1060. Recall that in Part 4, our best OOF score was 0.1070, so this represents a modest improvement, albeit a slight one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0361af-7498-45f6-9a3e-271f04222c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_params_optuna = pd.read_pickle(\n",
    "    Path.cwd().joinpath(\"data\").joinpath(\"CatBoost_params.pickle\")\n",
    ")\n",
    "\n",
    "print(\n",
    "    f'The best OOF RMSE score of the hyperparameter tuning is {pd.read_pickle(Path.cwd().joinpath(\"data\").joinpath(\"CatBoost_value.pickle\")):.4f}.'\n",
    ")\n",
    "print(f\"The corresponding values: {catboost_params_optuna}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc06f1f8-c2a6-4406-aa53-e645253532b2",
   "metadata": {},
   "source": [
    "# Retrain using the best parameters and predict\n",
    "\n",
    "After obtaining the most optimal parameters, we can proceed to retrain our model using the entire dataset, excluding the test portion, of course. For this we can use the `train_catboost` as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fd5584-9129-4e84-8cd7-8a0a98cde2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_catboost(\n",
    "    X: pd.DataFrame, y: pd.Series, catboost_params: dict\n",
    ") -> catboost.CatBoostRegressor:\n",
    "    \"\"\"\n",
    "    Train a CatBoostRegressor model using the provided data and parameters.\n",
    "\n",
    "    Parameters:\n",
    "        X (pd.DataFrame): The feature dataset.\n",
    "        y (pd.Series): The target variable.\n",
    "        catboost_params (dict): CatBoost hyperparameters.\n",
    "\n",
    "    Returns:\n",
    "        CatBoostRegressor: The trained CatBoost model.\n",
    "\n",
    "    This function takes the feature dataset `X`, the target variable `y`, and a dictionary of CatBoost\n",
    "    hyperparameters. It automatically detects categorical features in the dataset and trains a CatBoostRegressor\n",
    "    model with the specified parameters.\n",
    "\n",
    "    Example:\n",
    "        X, y = load_data()\n",
    "        catboost_params = {\n",
    "            'iterations': 1000,\n",
    "            'learning_rate': 0.1,\n",
    "            'depth': 6,\n",
    "            # ... other hyperparameters ...\n",
    "        }\n",
    "        model = train_catboost(X, y, catboost_params)\n",
    "    \"\"\"\n",
    "    categorical_features = X.select_dtypes(\"object\").columns.to_list()\n",
    "\n",
    "    catboost_train = catboost.Pool(\n",
    "        X,\n",
    "        y,\n",
    "        cat_features=categorical_features,\n",
    "    )\n",
    "\n",
    "    model = catboost.CatBoostRegressor(**catboost_params)\n",
    "    model.fit(\n",
    "        catboost_train,\n",
    "        verbose=utils.Configuration.verbose,\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac60091e-4e62-4197-b85d-b6e03b8e9cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model.train_catboost(X_train, y_train, catboost_params_optuna)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aeba7a3-5052-4002-9786-41d6a65b7667",
   "metadata": {},
   "source": [
    "Excellent! We've made good progress. Now, it's time for the final evaluation of our dataset using the test set. We can use the `predict_catboost` function for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83af087-cd62-463e-9360-8a549505f9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_catboost(\n",
    "    model: catboost.CatBoostRegressor,\n",
    "    X: pd.DataFrame,\n",
    "    thread_count: int = -1,\n",
    "    verbose: int = None,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Make predictions using a CatBoost model on the provided dataset.\n",
    "\n",
    "    Parameters:\n",
    "        model (catboost.CatBoostRegressor): The trained CatBoost model.\n",
    "        X (pd.DataFrame): The dataset for which predictions are to be made.\n",
    "        thread_count (int, optional): The number of threads for prediction. Default is -1 (auto).\n",
    "        verbose (int, optional): Verbosity level. Default is None.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Predicted values.\n",
    "\n",
    "    This function takes a trained CatBoost model, a dataset `X`, and optional parameters for\n",
    "    specifying the number of threads (`thread_count`) and verbosity (`verbose`) during prediction.\n",
    "    It returns an array of predicted values.\n",
    "\n",
    "    Example:\n",
    "        model = load_catboost_model()\n",
    "        X_new = load_new_data()\n",
    "        predictions = predict_catboost(model, X_new, thread_count=4, verbose=2)\n",
    "    \"\"\"\n",
    "    prediction = model.predict(data=X, thread_count=thread_count, verbose=verbose)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2849c3a2-924a-4d32-911c-b3aa58b3eaa5",
   "metadata": {},
   "source": [
    "To assess the predictions, we'll obtain both RMSE and R2 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35088904-5cc3-4e75-ae3f-76617f17d49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predict_model.predict_catboost(model=model, X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f3727e-ce09-4d5e-ac18-5542e92e1c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_prediction(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate regression evaluation metrics based on\n",
    "    true and predicted values.\n",
    "\n",
    "    Parameters:\n",
    "        y_true (array-like): True target values.\n",
    "        y_pred (array-like): Predicted values.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing Root Mean Squared Error (RMSE)\n",
    "        and R-squared (R2).\n",
    "\n",
    "    This function calculates RMSE and R2 to evaluate the goodness\n",
    "    of fit between the true target values and predicted values.\n",
    "\n",
    "    Example:\n",
    "        y_true = [3, 5, 7, 9]\n",
    "        y_pred = [2.8, 5.2, 7.1, 9.3]\n",
    "        rmse, r2 = score_prediction(y_true, y_pred)\n",
    "    \"\"\"\n",
    "    RMSE = np.sqrt(metrics.mean_squared_error(y_true, np.log10(y_pred)))\n",
    "    R2 = metrics.r2_score(y_true, y_pred)\n",
    "\n",
    "    return RMSE, R2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f901103b-4f36-40ab-94f3-4c4923f7a902",
   "metadata": {},
   "source": [
    "Superb! As you can see, the test set has an RMSE of 0.1101 and an R2 of 0.877. It's worth noting that the test set's RMSE is slightly higher than that of the training set, which is expected and suggests overfitting. Despite our efforts to prevent overfitting, it can be challenging to eliminate entirely. Nevertheless, it appears that we've done well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea70430-d780-4506-9199-86a800f40d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_model.score_prediction(y_pred=prediction, y_true=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9ee4df-3999-4cd1-a45d-1c0789b2e39c",
   "metadata": {},
   "source": [
    "Let's put the original values and prediction in a DataFrame so that we can evaluate them visually as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c330fd-2457-4025-9153-5e726b2b1012",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = (\n",
    "    pd.concat(\n",
    "        [y_test.reset_index(drop=True), pd.Series(prediction)], axis=\"columns\"\n",
    "    ).rename(columns={\"price\": \"original_values\", 0: \"predicted_values\"})\n",
    "    # .apply(lambda x: 10**x)\n",
    "    .assign(residuals=lambda df: df.original_values - df.predicted_values)\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cf1bb1-6b10-45fe-8f83-c54e3af146d6",
   "metadata": {},
   "source": [
    "As depicted below, our model demonstrates the ability to generalize effectively for unseen data, showcasing high R2 values and low RMSE. Additionally, examining the residuals reveals an even distribution, symbolizing robust model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026319cb-8455-4f66-992d-3c37109a4d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | fig-cap: \"Contrasting Predicted House Prices with Actual House Prices\"\n",
    "# | label: fig-fig1\n",
    "\n",
    "(\n",
    "    results.pipe(\n",
    "        lambda df: ggplot(df, aes(\"original_values\", \"predicted_values\"))\n",
    "        + geom_point()\n",
    "        + geom_smooth()\n",
    "        + geom_text(\n",
    "            x=5,\n",
    "            y=6.6,\n",
    "            label=f\"RMSE = {predict_model.score_prediction(y_pred=prediction, y_true=y_test)[0]:.4f}\",\n",
    "            fontface=\"bold\",\n",
    "        )\n",
    "        + geom_text(\n",
    "            x=4.965,\n",
    "            y=6.5,\n",
    "            label=f\"R2 = {predict_model.score_prediction(y_pred=prediction, y_true=y_test)[1]:.4f}\",\n",
    "            fontface=\"bold\",\n",
    "        )\n",
    "        + labs(\n",
    "            title=\"Contrasting Predicted House Prices with Actual House Prices\",\n",
    "            subtitle=\"\"\" The plot suggests that the model makes accurate predictions on the test data. This is evident from the low RMSE values, \n",
    "            signifying a high level of accuracy. Additionally, the high R2 value indicates that the model effectively accounts for a \n",
    "            substantial portion of the data's variance, demonstrating a strong alignment between the model's predictions and the actual data.\n",
    "            \"\"\",\n",
    "            x=\"log10 True Prices (EUR)\",\n",
    "            y=\"log10 Predicted Prices (EUR)\",\n",
    "        )\n",
    "        + theme(\n",
    "            plot_subtitle=element_text(\n",
    "                size=12, face=\"italic\"\n",
    "            ),  # Customize subtitle appearance\n",
    "            plot_title=element_text(size=15, face=\"bold\"),  # Customize title appearance\n",
    "        )\n",
    "        + ggsize(800, 600)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe5b56e-b7d9-4c27-9ad4-80bf14261e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | fig-cap: \"Assessing the Residuals from the Catboost Model\"\n",
    "# | label: fig-fig2\n",
    "\n",
    "(\n",
    "    results.pipe(lambda df: ggplot(df, aes(\"residuals\")) + geom_histogram(stat=\"bin\"))\n",
    "    + labs(\n",
    "        title=\"Assessing the Residuals from the Catboost Model\",\n",
    "        subtitle=\"\"\" Normally distributed residuals imply consistent and accurate model predictions, aligning with statistical assumptions.\n",
    "            \"\"\",\n",
    "        x=\"Distribution of Residuals\",\n",
    "        y=\"\",\n",
    "    )\n",
    "    + theme(\n",
    "        plot_subtitle=element_text(\n",
    "            size=12, face=\"italic\"\n",
    "        ),  # Customize subtitle appearance\n",
    "        plot_title=element_text(size=15, face=\"bold\"),  # Customize title appearance\n",
    "    )\n",
    "    + ggsize(800, 600)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dbf64f-1093-481e-bf62-72a1a3babe78",
   "metadata": {},
   "source": [
    "And there you have it! We reached the end of these series! ü•≥üéÜüéâüçæüçªüï∫ \n",
    "\n",
    "Over these five articles, we've shown how to build a reliable, high-performing machine learning model for real-time house price prediction. While there's always room for improvement, like exploring geolocation-based feature engineering, blending, and stacking, our aim was to provide a comprehensive guide from start to finish. We hope you've enjoyed this journey and gained inspiration and insights for your own projects.  \n",
    "\n",
    "Until next time! üíªüêçüêº"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
